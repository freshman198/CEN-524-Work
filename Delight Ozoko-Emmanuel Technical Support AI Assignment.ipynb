{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190a673b",
   "metadata": {},
   "source": [
    "# Technical Support Dataset - Based on my IT expereince\n",
    "# OZOKO-EMMANUEL DELIGHT\n",
    "# 20CJ027488\n",
    "# COMPUTER ENGINEERING\n",
    "\n",
    "#  CA ASSIGNMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_excel(\"technical_support_dataset.xlsx\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b046dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "df_encoded = pd.get_dummies(df, columns=['Issue_Category', 'Issue_Status'], drop_first=True)\n",
    "\n",
    "X = df_encoded.drop(['Conversation_ID', 'Customer_Issue', 'Tech_Response', 'Resolution_Time'], axis=1)\n",
    "y = df_encoded['Resolution_Time']\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Design Matrix (first 5 rows):\\n\", X_scaled[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda13999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8cde1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    return np.dot(X, w) + b\n",
    "\n",
    "def compute_gradients(X, y, y_pred):\n",
    "    m = len(y)\n",
    "    dw = (2/m) * np.dot(X.T, (y_pred - y))\n",
    "    db = (2/m) * np.sum(y_pred - y)\n",
    "    return dw, db\n",
    "\n",
    "def gradient_descent(X, y, lr=0.01, iterations=100):\n",
    "    n_features = X.shape[1]\n",
    "    w = np.zeros(n_features)\n",
    "    b = 0\n",
    "    mse_history = []\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        y_pred = predict(X, w, b)\n",
    "        mse_val = mse(y, y_pred)\n",
    "        mse_history.append(mse_val)\n",
    "\n",
    "        dw, db = compute_gradients(X, y, y_pred)\n",
    "        w -= lr * dw\n",
    "        b -= lr * db\n",
    "\n",
    "    return w, b, mse_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a99d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "w_opt, b_opt, mse_hist = gradient_descent(X_scaled, y, lr=0.01, iterations=100)\n",
    "\n",
    "# Predict final\n",
    "y_pred_final = predict(X_scaled, w_opt, b_opt)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Final MSE:\", mse(y, y_pred_final))\n",
    "print(\"Final MAE:\", mae(y, y_pred_final))\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(mse_hist)\n",
    "plt.title(\"MSE over Iterations\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
